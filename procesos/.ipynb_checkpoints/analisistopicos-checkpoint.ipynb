{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e054de7-56bc-437d-b94c-ce07bcc6fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\accar\\Notebooks\\ProyectoTesisMCD\\app\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datos\\\\topic_freq.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(directorio_actual)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# df = pd.read_csv(\"datos\\\\datos_carr_sel_prepro.csv\", encoding='latin1', sep=\";\")\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# return df\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Cargar archivos\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m topic_freq \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatos\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtopic_freq.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcp1252\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m topic_docs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatos\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtopic_docs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp1252\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datos\\\\topic_freq.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CARGAR LOS DATOS\n",
    "# =============================================================================\n",
    "\n",
    "directorio_actual = os.getcwd()\n",
    "print(directorio_actual)\n",
    "    # df = pd.read_csv(\"datos\\\\datos_carr_sel_prepro.csv\", encoding='latin1', sep=\";\")\n",
    "    # return df\n",
    "# Cargar archivos\n",
    "topic_freq = pd.read_csv(\"datos\\\\topic_freq.csv\", encoding='cp1252')\n",
    "topic_docs = pd.read_csv(\"datos\\\\topic_docs.csv\", encoding='cp1252')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75dbb565-3291-42ab-8ba7-a642592a262f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datos\\\\topic_freq.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m directorio_actual \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# df = pd.read_csv(\"datos\\\\datos_carr_sel_prepro.csv\", encoding='latin1', sep=\";\")\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# return df\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Cargar archivos\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m topic_freq \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatos\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtopic_freq.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcp1252\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m topic_docs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatos\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtopic_docs.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp1252\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datos\\\\topic_freq.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANÁLISIS DE RESULTADOS DEL MODELADO DE TÓPICOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Mostrar primeras filas para entender estructura\n",
    "print(\"\\n1. ESTRUCTURA DE LOS DATOS\")\n",
    "print(\"-\"*80)\n",
    "print(\"\\nTopic_freq (primeras 5 filas):\")\n",
    "print(topic_freq.head())\n",
    "print(f\"\\nColumnas: {list(topic_freq.columns)}\")\n",
    "print(f\"Dimensiones: {topic_freq.shape}\")\n",
    "\n",
    "print(\"\\nTopic_docs (primeras 5 filas):\")\n",
    "print(topic_docs.head())\n",
    "print(f\"\\nColumnas: {list(topic_docs.columns)}\")\n",
    "print(f\"Dimensiones: {topic_docs.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. ANÁLISIS DE FRECUENCIAS DE TÓPICOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. ANÁLISIS DE FRECUENCIAS DE TÓPICOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Excluir outliers (topic -1)\n",
    "topic_freq_clean = topic_freq[topic_freq['Topic'] != -1].copy()\n",
    "outliers = topic_freq[topic_freq['Topic'] == -1]\n",
    "\n",
    "# Estadísticas generales\n",
    "total_docs = topic_freq['Count'].sum()\n",
    "total_topics = len(topic_freq_clean)\n",
    "docs_outliers = outliers['Count'].values[0] if len(outliers) > 0 else 0\n",
    "\n",
    "print(f\"\\nTotal de documentos: {total_docs}\")\n",
    "print(f\"Total de tópicos identificados: {total_topics}\")\n",
    "print(f\"Documentos outliers: {docs_outliers} ({(docs_outliers/total_docs)*100:.1f}%)\")\n",
    "print(f\"Documentos clasificados: {total_docs - docs_outliers} ({((total_docs - docs_outliers)/total_docs)*100:.1f}%)\")\n",
    "\n",
    "# Calcular porcentajes\n",
    "topic_freq_clean['Percentage'] = (topic_freq_clean['Count'] / total_docs) * 100\n",
    "\n",
    "# Ordenar por frecuencia\n",
    "topic_freq_clean = topic_freq_clean.sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"DISTRIBUCIÓN DE DOCUMENTOS POR TÓPICO\")\n",
    "print(\"-\"*80)\n",
    "print(topic_freq_clean[['Topic', 'Name', 'Count', 'Percentage']].to_string(index=False))\n",
    "\n",
    "# =============================================================================\n",
    "# 3. ANÁLISIS DE PALABRAS CLAVE POR TÓPICO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. PALABRAS CLAVE POR TÓPICO (c-TF-IDF)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Asumiendo que las columnas de palabras clave están en topic_freq\n",
    "# Identificar columnas con palabras clave (típicamente: Representation o keywords)\n",
    "keyword_columns = [col for col in topic_freq.columns if 'representation' in col.lower() \n",
    "                   or 'keyword' in col.lower() or col.startswith('Word_')]\n",
    "\n",
    "if keyword_columns:\n",
    "    print(f\"\\nColumnas de palabras clave detectadas: {keyword_columns}\")\n",
    "    \n",
    "    for idx, row in topic_freq_clean.iterrows():\n",
    "        topic_id = row['Topic']\n",
    "        topic_name = row['Name']\n",
    "        count = row['Count']\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TÓPICO {topic_id}: {topic_name}\")\n",
    "        print(f\"Documentos: {count} ({row['Percentage']:.1f}%)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Extraer palabras clave\n",
    "        for col in keyword_columns:\n",
    "            if pd.notna(row[col]):\n",
    "                print(f\"  {col}: {row[col]}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. ANÁLISIS DE DOCUMENTOS ASIGNADOS A CADA TÓPICO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. ANÁLISIS DE DOCUMENTOS POR TÓPICO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verificar columna de topic en topic_docs\n",
    "topic_col = [col for col in topic_docs.columns if 'topic' in col.lower()][0]\n",
    "\n",
    "# Distribución de documentos\n",
    "topic_distribution = topic_docs[topic_col].value_counts().sort_index()\n",
    "\n",
    "print(f\"\\nDistribución de documentos:\")\n",
    "print(topic_distribution)\n",
    "\n",
    "# Estadísticas por tópico\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ESTADÍSTICAS DETALLADAS POR TÓPICO\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for topic_id in sorted(topic_distribution.index):\n",
    "    if topic_id == -1:\n",
    "        continue\n",
    "    \n",
    "    docs_topic = topic_docs[topic_docs[topic_col] == topic_id]\n",
    "    \n",
    "    print(f\"\\nTópico {topic_id}:\")\n",
    "    print(f\"  - Total documentos: {len(docs_topic)}\")\n",
    "    \n",
    "    # Si hay columnas de fecha/año\n",
    "    if 'año' in topic_docs.columns or 'year' in topic_docs.columns:\n",
    "        year_col = 'año' if 'año' in topic_docs.columns else 'year'\n",
    "        year_dist = docs_topic[year_col].value_counts().sort_index()\n",
    "        print(f\"  - Distribución por año:\")\n",
    "        for year, count in year_dist.items():\n",
    "            print(f\"      {year}: {count} docs\")\n",
    "    \n",
    "    # Si hay columnas de impacto\n",
    "    if 'vistas' in topic_docs.columns:\n",
    "        print(f\"  - Vistas promedio: {docs_topic['vistas'].mean():.0f}\")\n",
    "        print(f\"  - Vistas máximas: {docs_topic['vistas'].max():.0f}\")\n",
    "    \n",
    "    if 'descargas' in topic_docs.columns:\n",
    "        print(f\"  - Descargas promedio: {docs_topic['descargas'].mean():.0f}\")\n",
    "        print(f\"  - Descargas máximas: {docs_topic['descargas'].max():.0f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. DOCUMENTOS MÁS REPRESENTATIVOS POR TÓPICO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. DOCUMENTOS MÁS REPRESENTATIVOS POR TÓPICO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Si existe columna de probabilidad o distancia\n",
    "prob_col = [col for col in topic_docs.columns if 'prob' in col.lower() or 'distance' in col.lower()]\n",
    "\n",
    "for topic_id in sorted(topic_distribution.index):\n",
    "    if topic_id == -1:\n",
    "        continue\n",
    "    \n",
    "    docs_topic = topic_docs[topic_docs[topic_col] == topic_id].copy()\n",
    "    \n",
    "    # Ordenar por probabilidad (si existe)\n",
    "    if prob_col:\n",
    "        docs_topic = docs_topic.sort_values(prob_col[0], ascending=False)\n",
    "    elif 'vistas' in topic_docs.columns:\n",
    "        docs_topic = docs_topic.sort_values('vistas', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TÓPICO {topic_id} - Top 5 documentos más representativos\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Mostrar top 5\n",
    "    for idx, (i, row) in enumerate(docs_topic.head(5).iterrows(), 1):\n",
    "        print(f\"\\n{idx}. {row.get('titulo', row.get('title', 'Sin título'))}\")\n",
    "        if 'año' in row:\n",
    "            print(f\"   Año: {row['año']}\")\n",
    "        if 'vistas' in row:\n",
    "            print(f\"   Vistas: {row['vistas']}, Descargas: {row.get('descargas', 'N/A')}\")\n",
    "        if prob_col and prob_col[0] in row:\n",
    "            print(f\"   Probabilidad: {row[prob_col[0]]:.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 6. ANÁLISIS TEMPORAL (SI HAY DATOS DE AÑO)\n",
    "# =============================================================================\n",
    "\n",
    "if 'año' in topic_docs.columns or 'year' in topic_docs.columns:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"6. ANÁLISIS TEMPORAL DE TÓPICOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    year_col = 'año' if 'año' in topic_docs.columns else 'year'\n",
    "    \n",
    "    # Crear tabla de contingencia\n",
    "    temporal = pd.crosstab(\n",
    "        topic_docs[year_col], \n",
    "        topic_docs[topic_col],\n",
    "        margins=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTabla de contingencia (Año x Tópico):\")\n",
    "    print(temporal)\n",
    "    \n",
    "    # Calcular porcentajes por año\n",
    "    temporal_pct = pd.crosstab(\n",
    "        topic_docs[year_col], \n",
    "        topic_docs[topic_col],\n",
    "        normalize='index'\n",
    "    ) * 100\n",
    "    \n",
    "    print(\"\\nDistribución porcentual por año:\")\n",
    "    print(temporal_pct.round(1))\n",
    "    \n",
    "    # Identificar tendencias\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"TENDENCIAS TEMPORALES\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for topic_id in sorted(topic_distribution.index):\n",
    "        if topic_id == -1:\n",
    "            continue\n",
    "        \n",
    "        topic_by_year = temporal_pct[topic_id].dropna()\n",
    "        \n",
    "        if len(topic_by_year) > 3:\n",
    "            # Calcular tendencia simple\n",
    "            years = topic_by_year.index.astype(float)\n",
    "            values = topic_by_year.values\n",
    "            \n",
    "            # Comparar períodos\n",
    "            first_period = values[:len(values)//2].mean()\n",
    "            second_period = values[len(values)//2:].mean()\n",
    "            \n",
    "            if second_period > first_period * 1.3:\n",
    "                trend = \"↑ CRECIENTE\"\n",
    "            elif second_period < first_period * 0.7:\n",
    "                trend = \"↓ DECRECIENTE\"\n",
    "            else:\n",
    "                trend = \"→ ESTABLE\"\n",
    "            \n",
    "            print(f\"\\nTópico {topic_id}: {trend}\")\n",
    "            print(f\"  Primera mitad: {first_period:.1f}%\")\n",
    "            print(f\"  Segunda mitad: {second_period:.1f}%\")\n",
    "            print(f\"  Cambio: {((second_period/first_period - 1)*100):.1f}%\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. ANÁLISIS DE IMPACTO (VISTAS Y DESCARGAS)\n",
    "# =============================================================================\n",
    "\n",
    "if 'vistas' in topic_docs.columns:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"7. ANÁLISIS DE IMPACTO POR TÓPICO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    impact_stats = topic_docs.groupby(topic_col).agg({\n",
    "        'vistas': ['mean', 'median', 'max', 'sum'],\n",
    "        'descargas': ['mean', 'median', 'max', 'sum'] if 'descargas' in topic_docs.columns else []\n",
    "    }).round(0)\n",
    "    \n",
    "    print(\"\\nEstadísticas de impacto por tópico:\")\n",
    "    print(impact_stats)\n",
    "    \n",
    "    # Calcular ratio descarga/vista\n",
    "    if 'descargas' in topic_docs.columns:\n",
    "        impact_ratio = topic_docs.groupby(topic_col).apply(\n",
    "            lambda x: x['descargas'].sum() / x['vistas'].sum()\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\"RATIO DESCARGAS/VISTAS POR TÓPICO\")\n",
    "        print(\"-\"*80)\n",
    "        for topic_id, ratio in impact_ratio.items():\n",
    "            if topic_id != -1:\n",
    "                print(f\"Tópico {topic_id}: {ratio:.2f}\")\n",
    "    \n",
    "    # Identificar documentos de alto impacto por tópico\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"DOCUMENTOS DE ALTO IMPACTO (>400 VISTAS) POR TÓPICO\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    high_impact = topic_docs[topic_docs['vistas'] > 400]\n",
    "    impact_by_topic = high_impact.groupby(topic_col).size()\n",
    "    \n",
    "    for topic_id, count in impact_by_topic.items():\n",
    "        if topic_id != -1:\n",
    "            pct = (count / len(topic_docs[topic_docs[topic_col] == topic_id])) * 100\n",
    "            print(f\"Tópico {topic_id}: {count} docs ({pct:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. MÉTRICAS DE CALIDAD DEL MODELADO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"8. MÉTRICAS DE CALIDAD DEL MODELADO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Índice de Herfindahl-Hirschman (concentración)\n",
    "topic_proportions = topic_freq_clean['Count'] / topic_freq_clean['Count'].sum()\n",
    "hhi = (topic_proportions ** 2).sum()\n",
    "\n",
    "print(f\"\\nÍndice de Herfindahl-Hirschman (HHI): {hhi:.3f}\")\n",
    "if hhi > 0.25:\n",
    "    print(\"  → Alta concentración: pocos tópicos dominan\")\n",
    "elif hhi > 0.15:\n",
    "    print(\"  → Concentración moderada\")\n",
    "else:\n",
    "    print(\"  → Baja concentración: distribución equilibrada\")\n",
    "\n",
    "# Entropía (diversidad)\n",
    "entropy = -(topic_proportions * np.log(topic_proportions)).sum()\n",
    "max_entropy = np.log(len(topic_proportions))\n",
    "normalized_entropy = entropy / max_entropy\n",
    "\n",
    "print(f\"\\nEntropía normalizada: {normalized_entropy:.3f}\")\n",
    "print(f\"  → Diversidad temática: {normalized_entropy*100:.1f}%\")\n",
    "\n",
    "# Cobertura\n",
    "coverage = ((total_docs - docs_outliers) / total_docs) * 100\n",
    "print(f\"\\nCobertura del modelo: {coverage:.1f}%\")\n",
    "print(f\"  → {total_docs - docs_outliers} de {total_docs} documentos clasificados\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. GUARDAR RESULTADOS PARA EL CAPÍTULO 4\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"9. GUARDANDO RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear resumen para tablas del capítulo\n",
    "summary = topic_freq_clean[['Topic', 'Name', 'Count', 'Percentage']].copy()\n",
    "summary.columns = ['Tópico', 'Etiqueta', 'N° docs', '% corpus']\n",
    "summary.to_csv('resumen_topicos.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"✓ resumen_topicos.csv guardado\")\n",
    "\n",
    "# Crear tabla de impacto por tópico\n",
    "if 'vistas' in topic_docs.columns:\n",
    "    impact_table = topic_docs.groupby(topic_col).agg({\n",
    "        'vistas': 'mean',\n",
    "        'descargas': 'mean' if 'descargas' in topic_docs.columns else lambda x: 0\n",
    "    }).round(0)\n",
    "    impact_table.to_csv('impacto_por_topico.csv', encoding='utf-8-sig')\n",
    "    print(\"✓ impacto_por_topico.csv guardado\")\n",
    "\n",
    "# Crear tabla temporal\n",
    "if 'año' in topic_docs.columns or 'year' in topic_docs.columns:\n",
    "    temporal_pct.to_csv('evolucion_temporal_topicos.csv', encoding='utf-8-sig')\n",
    "    print(\"✓ evolucion_temporal_topicos.csv guardado\")\n",
    "\n",
    "# Top documentos por tópico\n",
    "for topic_id in sorted(topic_distribution.index):\n",
    "    if topic_id == -1:\n",
    "        continue\n",
    "    \n",
    "    docs_topic = topic_docs[topic_docs[topic_col] == topic_id].copy()\n",
    "    \n",
    "    if prob_col:\n",
    "        docs_topic = docs_topic.sort_values(prob_col[0], ascending=False)\n",
    "    elif 'vistas' in topic_docs.columns:\n",
    "        docs_topic = docs_topic.sort_values('vistas', ascending=False)\n",
    "    \n",
    "    top5 = docs_topic.head(5)[['titulo', 'año', 'vistas', 'descargas'] if 'vistas' in docs_topic.columns \n",
    "                                else ['titulo', 'año']]\n",
    "    \n",
    "    top5.to_csv(f'top5_topico_{topic_id}.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"✓ Top 5 documentos por cada tópico guardados\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ ANÁLISIS COMPLETADO\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd81628-a462-4883-89b0-a1a530ce7bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
